commit 34f36e6ee5bd7eff8b2adcd9fcaef369f752d82e
Author: Andi Kleen <ak@linux.intel.com>
Date:   Wed Aug 7 17:02:44 2024 -0700

    x86/mtrr: Check if fixed MTRRs exist before saving them
    
    commit 919f18f961c03d6694aa726c514184f2311a4614 upstream.
    
    MTRRs have an obsolete fixed variant for fine grained caching control
    of the 640K-1MB region that uses separate MSRs. This fixed variant has
    a separate capability bit in the MTRR capability MSR.
    
    So far all x86 CPUs which support MTRR have this separate bit set, so it
    went unnoticed that mtrr_save_state() does not check the capability bit
    before accessing the fixed MTRR MSRs.
    
    Though on a CPU that does not support the fixed MTRR capability this
    results in a #GP.  The #GP itself is harmless because the RDMSR fault is
    handled gracefully, but results in a WARN_ON().
    
    Add the missing capability check to prevent this.
    
    Fixes: 2b1f6278d77c ("[PATCH] x86: Save the MTRRs of the BSP before booting an AP")
    Signed-off-by: Andi Kleen <ak@linux.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/all/20240808000244.946864-1-ak@linux.intel.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

diff --git a/arch/x86/kernel/cpu/mtrr/mtrr.c b/arch/x86/kernel/cpu/mtrr/mtrr.c
index 9a19c800fe40..1935e20c6759 100644
--- a/arch/x86/kernel/cpu/mtrr/mtrr.c
+++ b/arch/x86/kernel/cpu/mtrr/mtrr.c
@@ -819,7 +819,7 @@ void mtrr_save_state(void)
 {
 	int first_cpu;
 
-	if (!mtrr_enabled())
+	if (!mtrr_enabled() || !mtrr_state.have_fixed)
 		return;
 
 	first_cpu = cpumask_first(cpu_online_mask);
